{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import idx2numpy\n",
    "import numpy as np\n",
    "import mne\n",
    "#import urllib.request\n",
    "#import os\n",
    "#import fnmatch\n",
    "#import pyedflib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function loads the EEG BCI Data and formats it into a dictionary that can be indexed by the task number (T0, T1, T2) with values formatted as a num_samples X 64 X 961(timesteps) ndarray\n",
    "# @params\n",
    "# Subject: Subject number to extract data from\n",
    "# Cases an array-like object that contains which experiments to extract (1-14)\n",
    "# @returns:\n",
    "# epoch containing data from subject in each case of cases\n",
    "def create_epochs(subject, cases):\n",
    "    #Load data\n",
    "    files = eegbci.load_data(subject, cases, './Data/')\n",
    "    # Convert to raw object\n",
    "    raws = [read_raw_edf(f, preload=True) for f in files]\n",
    "    #Combine all loaded runs\n",
    "    raw_obj = concatenate_raws(raws)\n",
    "    #Get Events\n",
    "    events, event_ids = mne.events_from_annotations(raw_obj, event_id='auto')\n",
    "    #Set epoch size\n",
    "    tmin, tmax = -1, 4\n",
    "    #Create epoch map\n",
    "    epochs = mne.Epochs(raw_obj, events, event_ids, tmin - 0.5, tmax + 0.5, baseline=None, preload=True)\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for cases group 1 T2 represents right fist and T1 represents left fist\n",
    "#for cases group 2 T2 represents both feet and T1 represents both fists\n",
    "#for both T0 represtents rest\n",
    "\n",
    "cases_1 = [3,4,7,8,11,12]\n",
    "cases_2 = [1,2,5,6,9,10,13,14]\n",
    "\n",
    "epochs_case1 = create_epochs(1, cases_1)\n",
    "epochs_case2 = create_epochs(1, cases_2)\n",
    "\n",
    "#Compute for 10 subjects\n",
    "for subject in range(2,10):\n",
    "    #Create epochs for current subject\n",
    "    epoch_curr_1 = create_epochs(subject, cases_1)\n",
    "    epoch_curr_2 = create_epochs(subject, cases_2)\n",
    "    #Concatenate to total dataset\n",
    "    epochs_case1 = mne.concatenate_epochs([epochs_case1, epoch_curr_1])\n",
    "    epochs_case2 = mne.concatenate_epochs([epochs_case1, epoch_curr_2])\n",
    "\n",
    "total_data = np.concatenate((epochs_case1['T2']._data, epochs_case1['T1']._data, epochs_case1['T0']._data, \n",
    "                             epochs_case2['T2']._data, epochs_case2['T1']._data, epochs_case2['T0']._data),\n",
    "                            axis=0)\n",
    "labels = np.concatenate((np.full((1,len(epochs_case1['T0']._data)),6), np.full((1,len(epochs_case1['T1']._data)),0), np.full((1,len(epochs_case1['T2']._data)),2),\n",
    "                         np.full((1,len(epochs_case2['T0']._data)),6), np.full((1,len(epochs_case2['T1']._data)),1), np.full((1,len(epochs_case2['T2']._data)),4) ), axis=1 )\n",
    "labels = labels[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3228, 64, 961)\n",
      "[6 6 6 ... 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(total_data))\n",
    "data_2D = np.reshape(total_data, (64*3228, 961))\n",
    "labels_2D = np.concatenate((np.full((1,64*len(epochs_case1['T0']._data)),6), np.full((1,64*len(epochs_case1['T1']._data)),0), np.full((1,64*len(epochs_case1['T2']._data)),2),\n",
    "                         np.full((1,64*len(epochs_case2['T0']._data)),6), np.full((1,64*len(epochs_case2['T1']._data)),1), np.full((1,64*len(epochs_case2['T2']._data)),4) ), axis=1 )\n",
    "\n",
    "labels_2D = labels_2D[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to idx file to maintain 3 dimensional shape\n",
    "idx2numpy.convert_to_file('FormattedPhysionetData.idx', total_data)\n",
    "df = pd.DataFrame(labels)\n",
    "df.to_csv('labels_3D.csv')\n",
    "\n",
    "#Save data to a 2D matrix representation for XGB classifier - Save as binary file for future use\n",
    "data_Dmat = xgb.DMatrix(data_2D, label=labels_2D)\n",
    "data_Dmat.save_binary('data_2D.buffer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD CODE THAT I DO NOT WANT TO LOSE JUST IN CASE\n",
    "# DO NOT RUN.\n",
    "\n",
    "\n",
    "# /**\n",
    "#  * Reads data from an EDF file, uses timestamps to label and format data into an (n x 64 x 656) matrix.\n",
    "#  * @param f - The EDF file to read from.\n",
    "#  * @param case_num - The case number to use for labeling.\n",
    "#  * @param sample_rate - The sample rate to use for slicing.\n",
    "#  * @returns A tuple containing the formatted data and labels.\n",
    "# This function is useful for reading data from an EDF file and formatting it into a matrix of size (n x 64 x 656).\n",
    "def format_data(f, case_num, sample_rate):\n",
    "    #read data from .edf file\n",
    "    file = pyedflib.EdfReader(f)\n",
    "    annotations = file.readAnnotations()\n",
    "    n = file.signals_in_file\n",
    "    signal_labels = file.getSignalLabels()\n",
    "    sigbufs = np.zeros((n,file.getNSamples()[0]))\n",
    "    for i in np.arange(n):\n",
    "        sigbufs[i,:]=file.readSignal(i)\n",
    "    file.close()\n",
    "    \n",
    "    if(case_num == 1):\n",
    "        task_dict = {'T1':0, 'T2':2, 'T0':6}\n",
    "    elif (case_num == 2):\n",
    "        task_dict = {'T1':1, 'T2':4, 'T0':6}\n",
    "    else:\n",
    "        print(\"Invalid case number\")\n",
    "        return -1;\n",
    "    #iterate through whole set slicing at indicies found in annotaions[0]\n",
    "    data = np.zeros((0,64,656))\n",
    "    labels = [0]\n",
    "    indicies = annotations[0] * sample_rate\n",
    "    for i in range(len(indicies)-1):\n",
    "        signal = sigbufs[:, i:int(indicies[i+1])]\n",
    "        label = task_dict[annotations[2][i]]\n",
    "        labels = np.append(labels, label)\n",
    "        if(len(signal[0]) > 656):\n",
    "            #remove last data points for those that are longer than 4.1s\n",
    "            signal = signal[:, 0:656]\n",
    "        elif(len(signal[0]) < 656):\n",
    "            #if less than desired pad with zeros\n",
    "            pad = np.zeros((64, 656-len(signal[0])))\n",
    "            signal = np.append(signal, pad, axis=1)\n",
    "        data = np.append(data, [signal], axis=0)\n",
    "\n",
    "    data = np.delete(data, 0, axis=0)\n",
    "    labels = np.delete(labels, 0, axis=0)\n",
    "    return data, labels\n",
    "\n",
    "    \n",
    "data,labels = format_data('./Data/files/S001/S001R10.edf', 2, 160)\n",
    "\n",
    "\n",
    "file = pyedflib.EdfReader('./Data/files/S009/S009R14.edf')\n",
    "annotations = file.readAnnotations()\n",
    "n = file.signals_in_file\n",
    "signal_labels = file.getSignalLabels()\n",
    "sigbufs = np.zeros((n,file.getNSamples()[0]))\n",
    "for i in np.arange(n):\n",
    "    sigbufs[i,:]=file.readSignal(i)\n",
    "file.close()\n",
    "\n",
    "print(annotations)\n",
    "rootdir = r'C:\\Users\\shortallb\\Documents\\GitHub\\brain-4ce\\PCA\\Data\\files'\n",
    "#for cases group 1 T2 represents right fist and T1 represents left fist\n",
    "#for cases group 2 T2 represents both feet and T1 represents both fists\n",
    "#for both T0 represtents rest\n",
    "cases1 = [ 'R03', 'R04', 'R07','R08','R11','R12']\n",
    "cases2 = [ 'R05', 'R06','R09','R10','R13','R14']\n",
    "SAMPLE_RATE = 160 #Hz\n",
    "data = np.empty((0,64,656))\n",
    "labels = []\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "            for case in cases1+cases2:\n",
    "                #skip .event files and seperate by case \n",
    "                if fnmatch.fnmatch(file, \"*\"+case+\".edf\") and case in cases1:\n",
    "                    data_tmp, labels_tmp = format_data(os.path.join(subdir, file), 1, SAMPLE_RATE)\n",
    "                    data = np.append(data, data_tmp, axis=0)\n",
    "                    labels = np.append(labels, labels_tmp, axis=0)\n",
    "                elif fnmatch.fnmatch(file, \"*\"+case+\".edf\") and case in cases2:\n",
    "                    data_tmp, labels_tmp = format_data(os.path.join(subdir, file), 2, SAMPLE_RATE)\n",
    "                    data = np.append(data, data_tmp, axis=0)\n",
    "                    labels = np.append(labels, labels_tmp, axis=0)\n",
    "                             "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
