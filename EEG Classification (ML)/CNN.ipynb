{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
"#########               taken from https://github.com/ravikiran-mane/FBCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get Data from Board\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\"\"\"Create the CNN Model\"\"\"\n",
    "class CNN(nn.Module):  \n",
    "    def __init__(self, input_size, kernel_size, conv_channels, \n",
    "                 dense_size, dropout):         \n",
    "        super(CNN, self).__init__()                  \n",
    "        self.cconv   = []  \n",
    "        self.MaxPool = nn.MaxPool2d((1, 2), (1, 2))  \n",
    "        self.ReLU    = nn.ReLU()\n",
    "        self.Dropout = nn.Dropout(dropout)        \n",
    "        self.batchnorm = []                \n",
    "        # ############ batchnorm ###########\n",
    "        for i in conv_channels:\n",
    "            self.batchnorm.append(nn.BatchNorm2d(i, eps=0.001, momentum=0.01,\n",
    "                                                 affine=True, track_running_stats=True).cuda())     \n",
    "        j = 0 ##### define CONV layer architecture: #####\n",
    "        for in_channels, out_channels in zip(conv_channels, conv_channels[1:]):                           \n",
    "            conv_i = nn.Conv2d(in_channels = in_channels, out_channels = out_channels,\n",
    "                                     kernel_size = kernel_size[j], #stride = (1, 2),\n",
    "                                     padding     = (kernel_size[j][0]//2, kernel_size[j][1]//2))            \n",
    "            self.cconv.append(conv_i)                \n",
    "            self.add_module('CNN_K{}_O{}'.format(kernel_size[j], out_channels), conv_i)\n",
    "            j += 1                            \n",
    "        self.flat_dim = self.get_output_dim(input_size, self.cconv)    \n",
    "        self.fc1 = nn.Linear(self.flat_dim, dense_size)\n",
    "        self.fc2 = nn.Linear(dense_size, 2)                \n",
    "\n",
    "    def get_output_dim(self, input_size, cconv):        \n",
    "        with torch.no_grad():\n",
    "            input = torch.ones(1,*input_size)              \n",
    "            for conv_i in cconv:                \n",
    "                input = self.MaxPool(conv_i(input))        \n",
    "                flatout = int(np.prod(input.size()[1:]))\n",
    "                print(\"Input shape : {} and flattened : {}\".format(input.shape, flatout))\n",
    "        return flatout \n",
    "        \n",
    "    def forward(self, input):        \n",
    "        for i, conv_i in enumerate(self.cconv):\n",
    "            input = conv_i(input)\n",
    "            input = self.batchnorm[i+1](input)\n",
    "            input = self.ReLU(input)        \n",
    "            input = self.MaxPool(input)                   \n",
    "        # flatten the CNN output     \n",
    "        out = input.view(-1, self.flat_dim) \n",
    "        out = self.fc1(out)                       \n",
    "        out = self.Dropout(out)        \n",
    "        out = self.fc2(out)      \n",
    "        return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Tune Hyperparameters\"\"\"\n",
    "\n",
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if dev.type == 'cuda':\n",
    "   print('Your GPU device name :', torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 150 \n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-4  \n",
    "batch_size = 64\n",
    "verbose = 1\n",
    "\n",
    "# define kernel size in terms of ms length \n",
    "fs = 160 #Hz\n",
    "time_window = 100 #ms\n",
    "width = time_window*fs//1000 \n",
    "\n",
    "# convolution parameters \n",
    "h, w = 3, 1\n",
    "\n",
    "kernel_size = [(h, w*width), (h, w*width), (h, w*width),(h, w*width), (h, w*width), (h, w*width)]\n",
    "conv_chan = [1, 8, 16, 32, 64] \n",
    "\n",
    "table = pd.DataFrame(columns = ['Train_Acc', 'Val_Acc', 'Test_Acc', 'Epoch']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the architecture\n",
    "\n",
    "#input_size = DEFINE AN INPUT SIZE FOR DATA\n",
    "\n",
    "model = CNN(input_size    = input_size, \n",
    "              kernel_size   = kernel_size, \n",
    "              conv_channels = conv_chan,\n",
    "              dense_size    = 256, \n",
    "              dropout       = 0.5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\BU\\Senior Design\\brain-4ce\\EEG Classification (ML)\\CNN.ipynb Cell 7\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BU/Senior%20Design/brain-4ce/EEG%20Classification%20%28ML%29/CNN.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# optimizer and the loss function definition \u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/BU/Senior%20Design/brain-4ce/EEG%20Classification%20%28ML%29/CNN.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr \u001b[39m=\u001b[39m learning_rate, weight_decay \u001b[39m=\u001b[39m weight_decay)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BU/Senior%20Design/brain-4ce/EEG%20Classification%20%28ML%29/CNN.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m criterion \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BU/Senior%20Design/brain-4ce/EEG%20Classification%20%28ML%29/CNN.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39mto(dev)  \n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# optimizer and the loss function definition \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "model.to(dev)  \n",
    "criterion.to(dev)    \n",
    "print(\"Model architecture >>>\", model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Training Loop\"\"\"\n",
    "from Train_Model import train_model\n",
    "best_model, train_losses, val_losses, train_accs, val_accs, info =\\\n",
    "#    train_model(model, data['dset_loaders'], data['dset_sizes'], \n",
    "#                criterion, optimizer, dev, lr_scheduler = None, num_epochs = num_epochs, verbose = verbose)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
